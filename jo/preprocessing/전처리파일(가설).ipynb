{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751ecc3-614c-4646-89ea-95fcda079f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# ê¸°ë³¸ ê²½ë¡œ\n",
    "base_path = r\"C:\\Users\\henaj\\Downloads\\278.êµ­ë‚´ ì—¬í–‰ë¡œê·¸ ë°ì´í„°(ë™ë¶€ê¶Œ)\\01-1.ì •ì‹ê°œë°©ë°ì´í„°\\Training\\01.ì›ì²œë°ì´í„°\"\n",
    "### TASK 1: í™œë™ë‚´ì—­ + ì—¬í–‰ì§€ ë³‘í•©\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "activity_df = pd.read_csv(os.path.join(base_path, 'tn_activity_his_í™œë™ë‚´ì—­_B.csv'), encoding='utf-8')\n",
    "traveller_master_df = pd.read_csv(os.path.join(base_path, 'tn_traveller_master_ì—¬í–‰ê° Master_B.csv'), encoding='utf-8')\n",
    "travel_df = pd.read_csv(os.path.join(base_path, 'tn_travel_ì—¬í–‰_B.csv'), encoding='utf-8')\n",
    "# Step 1: traveller_master_dfì—ì„œ TRAVELER_ID, TRAVEL_STATUS_DESTINATION ì¶”ì¶œ\n",
    "traveller_dest = traveller_master_df[['TRAVELER_ID', 'TRAVEL_STATUS_DESTINATION']]\n",
    "# Step 2: travel_dfì—ì„œ TRAVEL_ID, TRAVELER_ID ì¶”ì¶œ\n",
    "travel_id_map = travel_df[['TRAVEL_ID', 'TRAVELER_ID']]\n",
    "# Step 3: TRAVELER_ID ê¸°ì¤€ìœ¼ë¡œ TRAVEL_IDì— TRAVEL_STATUS_DESTINATION ì—°ê²°\n",
    "merged_travel = pd.merge(travel_id_map, traveller_dest, on='TRAVELER_ID', how='inner')  # TRAVEL_ID + DEST\n",
    "# Step 4: í™œë™ë‚´ì—­ê³¼ ë³‘í•© (TRAVEL_ID ê¸°ì¤€)\n",
    "activity_df_trimmed = activity_df[['TRAVEL_ID', 'ACTIVITY_TYPE_CD']]\n",
    "result1 = pd.merge(activity_df_trimmed, merged_travel[['TRAVEL_ID', 'TRAVEL_STATUS_DESTINATION']], on='TRAVEL_ID', how='inner')\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "result1.to_csv(os.path.join(base_path, 'analysis1.csv'), index=False, encoding='utf-8-sig')\n",
    "### TASK 2: ìˆ™ë°•ì†Œë¹„ë‚´ì—­ ì •ì œ\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "lodge_df = pd.read_csv(os.path.join(base_path, 'tn_lodge_consume_his_ìˆ™ë°•ì†Œë¹„ë‚´ì—­_B.csv'), encoding='utf-8')\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì„ íƒ\n",
    "lodge_df_trimmed = lodge_df[['TRAVEL_ID', 'LODGING_TYPE_CD', 'LOTNO_ADDR']]\n",
    "# ê²°ì¸¡ì¹˜ ì œê±° (ê³µë°±, NaN, 'N/A', 'NULL')\n",
    "lodge_df_cleaned = lodge_df_trimmed.replace(['', ' ', 'N/A', 'NULL'], pd.NA).dropna()\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "lodge_df_cleaned.to_csv(os.path.join(base_path, 'analysis2.csv'), index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "# 1. ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "analysis1 = pd.read_csv(os.path.join(base_path, 'analysis1.csv'), encoding='utf-8-sig')\n",
    "analysis2 = pd.read_csv(os.path.join(base_path, 'analysis2.csv'), encoding='utf-8-sig')\n",
    "# 2. revisit ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "visit_info = pd.read_csv(os.path.join(base_path, 'tn_visit_area_info_ë°©ë¬¸ìì •ë³´_B.csv'), encoding='utf-8')\n",
    "revisit_info = visit_info[['TRAVEL_ID', 'REVISIT_INTENTION']]\n",
    "# 3. analysis1ê³¼ ë³‘í•©\n",
    "analysis1_updated = pd.merge(analysis1, revisit_info, on='TRAVEL_ID', how='left')\n",
    "# 4. analysis2ì™€ ë³‘í•©\n",
    "analysis2_updated = pd.merge(analysis2, revisit_info, on='TRAVEL_ID', how='left')\n",
    "# 5. ë‹¤ì‹œ ì €ì¥\n",
    "analysis1_updated.to_csv(os.path.join(base_path, 'analysis1.csv'), index=False, encoding='utf-8-sig')\n",
    "analysis2_updated.to_csv(os.path.join(base_path, 'analysis2.csv'), index=False, encoding='utf-8-sig')\n",
    "# 1. ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "analysis1 = pd.read_csv(os.path.join(base_path, 'analysis1.csv'), encoding='utf-8-sig')\n",
    "analysis2 = pd.read_csv(os.path.join(base_path, 'analysis2.csv'), encoding='utf-8-sig')\n",
    "# 2. ë°©ë¬¸ì ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "visit_info = pd.read_csv(\n",
    "    os.path.join(base_path, 'tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_B.csv'),\n",
    "    encoding='utf-8-sig',\n",
    "    low_memory=False  # <-- ê²½ê³  ë°©ì§€\n",
    ")revisit_info = visit_info[['TRAVEL_ID', 'REVISIT_INTENTION']]\n",
    "# 3. ë³‘í•©\n",
    "analysis1_updated = pd.merge(analysis1, revisit_info, on='TRAVEL_ID', how='left')\n",
    "analysis2_updated = pd.merge(analysis2, revisit_info, on='TRAVEL_ID', how='left')\n",
    "# 4. ì €ì¥\n",
    "analysis1_updated.to_csv(os.path.join(base_path, 'analysis1.csv'), index=False, encoding='utf-8-sig')\n",
    "analysis2_updated.to_csv(os.path.join(base_path, 'analysis2.csv'), index=False, encoding='utf-8-sig')\n",
    "print(\"ğŸ‰ ë³‘í•© ì™„ë£Œ! REVISIT_INTENTION ì—´ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "analysis_df = pd.read_csv(f'{base_path}\\\\analysis2.csv')\n",
    "visit_info_df = pd.read_csv(f'{base_path}\\\\tn_visit_area_info_ë°©ë¬¸ì§€ì •ë³´_B.csv')\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì„ íƒ (TRAVEL_ID, REVISIT_INTENTION)\n",
    "visit_info_df = visit_info_df[['TRAVEL_ID', 'REVISIT_INTENTION']]\n",
    "# ì¤‘ë³µ ì œê±° (ë™ì¼ TRAVEL_IDì— ì—¬ëŸ¬ ê°’ì´ ìˆì„ ê²½ìš° ì²« ë²ˆì§¸ë§Œ ë‚¨ê¹€)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
